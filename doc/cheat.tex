\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{authblk}
\usepackage{algorithm}
\usepackage{algorithmic}

\newcommand{\bbeta}{\boldsymbol\beta}
\newcommand{\bt}{\boldsymbol\tau}
\newcommand{\bta}{\boldsymbol\ta}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\st}{v_{\ta}}
\newcommand{\ta}{\theta}
\newcommand{\lla}{\longleftarrow}
\newcommand{\G}{\mathcal{G}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\Normal}{\mathcal{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bX}{\mathbf{X}}

\title{Fuzzy Graph Clustering Algorithms for Detecting Test Collusion Groups and Leaked Items}

\author[1]{Oren Livne}
\affil[1]{Educational Testing Service, 660 Rosedale Road, Attn: MS-12, T-197, Princeton, NJ 08540. Email: olivne@ets.org}
\date{\today}
	
\begin{document}
\maketitle

\begin{abstract}
We consider the problem of identifying groups of students that have seen a significant subset (20\% - 40\%) of leaked items before taking the test, and whose responses to these items are therefore highly correlated. Multiple cheater sets may exist and overlap, corresponding to overlapping leaked item sets. We only assume the scores and response times on the current test are available, and no  prior knowledge about the students or items. We model the problem as biclustering of an undirected bipartite graph of students and items, where edge weights measure the discrepancy between the student's predicted success on the item (estimated for instance by IRT) and his/her actual performance. First, we generate low-dimensional feature vectors of students and items via graph Laplacian relaxation, from which meaningful distances between close neighbors are derived. Then, we create a mini-clustering of the students using a top-down hierarchical K-means algorithm. Clusters are fuzzy, allowing a student to belong to multiple clusters. Finally, we look for clusters of unusually large size and strength and flag them as likely collusion groups. The computational complexity is linear in the number of students and items. We demonstrate the approach for synthetic data and for a real-world data of 1636 students and 170 items. {\bf Add cheater set reconstruction accuracy here once we have implemented the method.}
\end{abstract}

\section{Introduction}
Test collusion is defined as the sharing of test materials or answers to test items before or during a test, and poses a serious problem to the validity of score interpretation. Collusion is typically indicated by a high response correlation among a subset of test takers (hereafter denoted ``students'') involved in the collusion (a ``collusion group'') for a subset of the items (``leaked items''). The two major challenges in detecting collusion are (a) the leaked item sets are unknown; (b) collusion groups may overlap; and (c) leaked items of different collusion groups may also overlap.

We assume that the leaked item subsets are large (20\% - 40\% of all items in our applications), which makes it possible to detect collusion sets. Notwithstanding, we only assume the scores and response times on the current test are available. No prior knowledge about the students or items is assumed (e.g., whether items were used on previous tests and might have a higher probability of leakage).

The development of statistical methods for detecting collusion has become a a hot research topic in test security \cite{refs}, and pose interesting statistical and computational challenges. Searching through all possible portions is both computationally expensive or prohibitive, and decreases the detection power or increase the false-positive rate of a statistical test.

In particular, computational graph-based methods have been suggested. In \cite{belov}, an unweighted, undirected student similarity graph is formulated based on the $\omega$ response similarity index is constructed. An edge is added if and only if the similarity index exceeds a pre-determined significance level. The method then searches for the largest clique, tests if its size is significantly large (in a clique size distribution estimated using Monte-Carlo simulations); if so, removes it from the graph, and looks for the largest clique; etc. The drawbacks of this method are (a) the graph includes only students as nodes; items are basically aggregated in the response similarity index, making it hard to detect which items were leaked; and (b) looking for perfect cliques is very restrictive; it depends on the particular threshold used to include edges. In practice, collusion groups may be near-cliques or just strongly connected clusters, where connectivity is not defined by the presence of an edge between two nodes, but when their graph neighborhoods are similar, that is, there are many short paths linking them (whether they are directly connected or not).

We propose a different graph-based biclustering approach inspired by {\it multiscale methods} -- a direct application of \cite[Sec.~10]{msgd}. We build a bipartite graph of students and items, where edge weights also take into account response times. Assuming cheaters have a faster response time than non-cheaters, they will be more strongly connected to leaked items. We then find a {\it bi-clustering} of the graph: clustering in one partition, which is tied with clustering in the other.

The algorithm first builds feature vectors using a relaxation process of the graph Laplacian. These feature vectors give rise to meaningful distances between close neighbors on the graph. Relaxation-based graph distances were first developed for undirected graphs in \cite{safro} and applied to solving graph Laplacian systems in \cite{lamg}, and to finding near-cliques of descendants sharing the same DNA haplotype in \cite{primal}. Here, we apply relaxation-based distances to the bipartite graph, generate a {\it miniclustering} of students that have small distances, and look for large, strongly-connected clusters. Clusters are allowed to overlap. We believe that this approach is more flexible than looking for exact cliques, and less susceptible to the precise value of edge thresholding.

The paper is organized as follows. Sec.~\ref{model} describes how the graph is constructed from response data. The biclustering algorithm is described in Sec.~\ref{biclustering}. Numerical results are detailed in Sec.~\ref{results}, followed by concluding remarks on the generalization of the method in Sec.~\ref{remarks}.

\section{Bipartite Graph Formulation}
\label{model}
We assume $M$ persons take a test consisting of $N$ items. Let $x_{mn}$ be the score of student $m$ on item $n$ and $t_{mn} > 0$ the response time. We assume dichotomous items, $x_{mn} \in \left\{0,1\right\}$, although the method is applicable to any type of item scoring (see \ref{remarks}).

 $x_{mn} \in [0,1]$. We define a bipartite graph $G$ consisting of two disjoint sets of nodes (``partitions''), $\{a_1,a_2,\ldots,a_M\}$ for students, and $\{b_1,b_2,\ldots,b_N\}$ for items with no intra-partition links; the only links are from some $a_m$ to some $b_n$, with a weight $w_{mn}$ that reflects the strength of connection between a student and an item. We choose $w_{nm} := x_{nm}/t_{nm}^s$, where $s > 0$ is a hyper-parameter that can be chosen higher or lower to emphasize or de-emphasize fast response times.


\section{Biclustering Algorithm}
\label{biclustering}
Biclustering is clustering in one partition that is tied with clustering in the other. Two students are clustered together not only when they have largely have the same answers to all items, but also when they answered the same items that largely belong to the same class. Two items belong to the same class if they have been answered roughly the by the same cluster of students. The clustering is fuzzy: a student may belong to multiple clusters and and item may participate in multiple classes. 

\subsection{Relaxation-based Feature Vectors}
The Biclustering algorithm starts by assigning each $a_m$ with a normalized random feature vector $\alpha_m \in \R^q$:
\begin{equation}
\begin{split}
  \alpha_m = \left[ (\alpha_m^1,\alpha_m^1,\ldots,\alpha_m^q) \right]_{normalized} =  \\
  (\alpha_m^1,\alpha_m^1,\ldots,\alpha_m^q) /
  \left[ \sum_{i=1}^q (\alpha_m^i)^2 \right]^{1/2},
\end{split}
\end{equation}
where each $\alpha_m^i$ is a random number uniformly distributed in the interval $[-1,1]$. 

Next, the algorithm repeats $K$ times the following alternating pair of normalized-averaging steps:
\begin{equation}
\begin{split}
(1) \quad \beta_n = \left[ \sum_m w_{mn} \alpha_m / \sum_m w_{mn} \right]_{normalized}, \quad (n=1,\ldots,N) \\
(2) \quad \alpha_m = \left[ \sum_n w_{mn} \beta_n / \sum_n w_{mn} \right]_{normalized}, \quad (m=1,\ldots,M) 
\end{split}
\label{eqn:bistep}
\end{equation}
Each iteration is equivalent to a Gauss-Seidel relaxation sweep for the graph Laplacian \cite{lamg} on each of the nodal vectors $y^i := (\alpha_1^i,\dots,\alpha_M^i,\beta_1^i,\dots,\beta_N^i)$, $i=1,\dots,K$, followed by the normalization step.

After these steps, two students $a_m$ and $a_{m'}$ who had a similar response pattern would clearly have small distance between them:
\begin{equation}
d_{mm'} := \|\alpha_m - \alpha_{m'} \|_2 \ll 1\,.
\end{equation}
Moreover, $d_{mm'}$ will be small even if they responded correctly to different items, as long as most of the items they responded the same to were answered similarly by a large set of students; and so on, going back and forth between students and items.

In particular, two students in the same collusion group will have a small distance, allowing us to discover collusion groups as clusters of small radius.

The number of steps $K$ should be small to keep the algorithm efficient as well as retain meaningful information in the feature vectors $\alpha^i, \beta^i$ (as $K \rightarrow \infty$, these vectors tend to a constant over each connected component of $G$, as the averaging extends over the entire component). The $d_{mm'}$ metric can thus only be used to identify small neighborhoods in each partition. In other words, it can be used for defining in each partition many \underline{mini-clusters} of neighbors, which is done efficiently using the hierarchical k-means algorithm described next.

\subsection{Student Mini-Clustering}
\label{miniclustering}
First, we build a hierarchical clustering of students based on their feature vectors using the method of \cite{miniclustering}. Each student corresponds to a $q$-dimensional point $\alpha_n$. The hierarchy consists of levels $\left\{\cG^s\right\}_{s=1}^S$ where each level is a set of person groups $\cG_s := \left\{G_l\right\}_{l=1}^{P^s}$.

$G^1$ consists of a single (or few groups obtained by k-means). Each $G^s$, $s=2,\dots,S$ is obtained from the parent level $G^{s-1}$ by (1) sub-dividing each parent group into $b$ child groups using k-means within the group; and (2) improving all child centers by global k-means, where each point is reassigned to the closest of its $r \approx 5$ nearest centers. This requires maintaining at every level approximate neighboring center lists of each point and each center, which are conveniently and derived from the parent level's neighbor lists (for a child center, we use the nearest $r$ centers within its parent's child centers and the parent's neighbors' child centers; similarly for a point). The entire process requires $O(r I P \log P)$ time and $O(r I P)$ storage.

\subsection{Unfinished ideas}
The basic open question: how to detect collusion groups from the clustering?
\begin{itemize}
	\item \underline{Fuzzy hierarchical clustering.} Instead of the disjoint miniclusters one can use the $d_{mm'}$ metric to build in each partition \underline{fuzzy} mini-clusters, where each node has a \underline{probability} of belonging to each one of possible \underline{several} mini-clusters. The same can then be done at all levels of the hierarchical clustering. This allows a student to participate in multiple collusion groups.
	\item \underline{Out of distribution clusters.} One could try several maximum radius threshold for the miniclustering, and see whether we find unusually large clusters of small radius, which may be candidate collusion groups. In this case there are only two scales: nodes and clusters, similar to \cite{primal}.
  \item \underline{Bottom-up clustering.} gradually build collusion groups - smaller miniclusters, from which we construct bigger clusters by emphasizing ``aggregative properties'', in this case, perhaps items that may seem like they were leaked. Then we proceed in the standard way: to create a bipartite graph whose nodes are the mini-clusters, we need to define  the affinity (the weight of the link) between any mini-cluster $A_p$ in the first partition and any mini-cluster $B_q$ in the second partition. A natural definition is
\begin{equation}
W_{pq} = \frac{\sum_{n,m} P^a_{mp}P^b_{nq}{w_{mn}}^\eta}{ \sum_{n,m}P^a_{mp}P^b_{nq}}
\label{eqn:b2}
\end{equation}
where
\begin{equation}
P^a_{mp} = Prob \left[a_m \in A_p\right], \quad P^b_{nq} = Prob \left[ b_n \in B_q \right]
\end{equation}
and $\eta>0$ is a hyper-parameter that can be chosen higher or lower to emphasize or de-emphasize strong links.
\end{itemize}

\section{Results}
\label{results}

\section{Concluding Remarks}
\label{remarks}

\begin{itemize}
	\item {Continuous scores.} The weight definition $w_{nm} := x_{nm}/t_{nm}^q$ is an unambitious measure of response quality for ,dichotomous items, because there is a link if and only if the response was correct, and the mapping from times to weights is one-to-one and monotonically decreasing. For continuous scores, this would be ambiguous: a score and response time results in the same weight as a lower score and faster response time, or vice versa. If this is undesirable for the application, one can redefine $w_{nm}$ to have a partial order first in scores (say, piecewise constant on score intervals) and then a secondary partial order inversely proportional to the response time within each score interval.
\end{itemize}

\section{Acknowledgments}
The work reported herein was supported by Educational Testing Service Research Allocation Project {\bf TBD...}.

The author would like to thank Achi Brandt for his insightful suggestions regarding the modeling and algorithm.

\bibliographystyle{plain}
\bibliography{cheat}

\end{document}