\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{authblk}
\usepackage{algorithm}
\usepackage{algorithmic}

\newcommand{\bbeta}{\boldsymbol\beta}
\newcommand{\bt}{\boldsymbol\tau}
\newcommand{\bta}{\boldsymbol\ta}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\st}{v_{\ta}}
\newcommand{\ta}{\theta}
\newcommand{\lla}{\longleftarrow}
\newcommand{\G}{\mathcal{G}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\Normal}{\mathcal{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bX}{\mathbf{X}}

\title{Non-parametric Item Response Theory: Modeling and Fast MCMC Estimation}

\author[1]{Oren Livne}
\affil[1]{Educational Testing Service, 660 Rosedale Road, Attn: MS-12, T-197, Princeton, NJ 08540. Email: olivne@ets.org}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
We describe a non-parametric Item Response Theory (IRT) model that estimates both student latent abilities and item response functions, without assuming a specific parametric form or prior distributions. We describe a fast multilevel Monte-Carlo Markov Chain algorithm for estimating the model parameters. Multileveling is used to both speed up MCMC equilibration and define a continuation process that gradually refines the item response function resolution, along with simulated annealing controlling Monte-Carlo updates of latent ability variables. We argue that this formulation can reduce over-fitting, model more general item types and lends itself to faster computation compared with parametric IRT models.
\end{abstract}

\section{Introduction}
Item response theory (IRT) (also known as latent trait theory) is a psychometric paradigm for the design, analysis, and scoring of tests, questionnaires, and similar instruments measuring abilities, attitudes, or other variables. It is a theory of testing based on the relationship between individuals' performances on a test item and the test takers' levels of performance on an overall measure of the ability that item was designed to measure. We consider two challenges: (a) formulating an IRT model that uses minimal assumptions to reduce bias in estimating student abilities and item difficulty; (b) developing a fast numerical solution for estimating the model parameters.

First, we present a new computational model that estimates person abilities and Item Response Functions (IRFs). This falls under the category of Non-parametric IRT (NIRT): the IRF is not presumed to have a specified form, but instead represented as numerical functions and found as part of the model. There is a large body of literature on NIRT; see \cite{sijtsma} for a survey. The presented formulation offers several modeling advantages over other IRT approaches:
\begin{itemize}
	\item Individual person latent abilities are directly estimated using a Monte-Carlo 
	Markov Chain (MCMC) simulation, as opposed to first integrating over the latent ability distribution to estimate item parameters first, then sampling from the posterior distribution to obtain latent abilities. This reduces bias
	\item General item types can be modeled without specifying a different IRF for each item,
	including non-monotonic IRFs, e.g., attractive distractor \cite{attractive_distractor}. NIRT should be applicable to large carefully curated item sets (where only items with ``good'' IRFs are used after heavy calibration and filtering) as well as small item sets (where IRFs may be more variable) because IRFs are determined from the response data, as opposed to assuming a pre-determined shape (e.g., a two- or three-parameter logistic model (2PL, 3PL) \cite{junker}) that may be approximate or wrong. It can be applied when all persons response to the same set of items, or when each person responds to a different subset of items (as in NAEP \cite{matt02}).
	\item While on the surface the model has more parameters than parametric IRT, over-fitting can be reduced and controlled by adaptively binning in the IRF's numerical representation.
\end{itemize}

Secondly, we develop a fast multilevel MCMC algorithm for estimating the model parameters. The MCMC formulation lends itself to a much faster computation than models that estimate item parameters by integrating out the latent ability dimension. These use a Newton-Raphson \cite{haberman} or Expectation-Maximization to maximize the likelihood function. Many steps are typically required to converge to a local maximum (not guaranteed to be near the global maximum), since these search methods visit many states that are far from the solution before honing in the correct its basin of attraction, and/or require step damping to maintain stability. Furthermore, each step requires a costly evaluation of a multi-dimensional integral.

In contrast, we run MCMC with a {\it continuation method}: we start from a coarse resolution of the IRF function, and estimate its parameters along with the latent abilities of large groups of students using MCMC. We then gradually increase the IRF resolution while refining student groups into smaller groups; the solution to the model at a certain resolution serves as the initial guess to the next-higher resolution model. In this way we confine the search to the relevant part of the parameter space.

Monte-Carlo (MC) process is called {\it statistically optimal} if it attains accuracy $\varepsilon$ in a target quantity (e.g., the mean latent ability of sub-populations of interest) in $O(\sigma_2 \varepsilon^{-2})$ samples, where $\sigma$ is the standard deviation of the target quantity. This is the theoretical lower bound, as this is the complexity of calculating any simple average by statistical sampling, e.g., the frequency of heads in coin tossing, and we therefore set it as our goal. However, MC often encounters critical slowing down (CSD): the number passes needed to produce a new (independent) sample increases, typically as a power of the number of parameters. To mitigate that, we develop a {\it multilevel MC} algorithm: in addition to updating individual parameters, it also applied collective updates to groups of correlated parameters. By updating groups of various scales, CSD is avoided and the algorithm is statistically optimal, with a linear run-time complexity in the number of persons and items. 

The multilevel methodology offers other benefits (e.g., supporting adaptive grids in the IRF representation, Sec.~\ref{adaptive_grid}) and could be used to speed up other MCMC models beyond IRT.

We describe the model in Section~\ref{model}. The multilevel MCMC algorithm for estimating model parameters is presented in Section~\ref{mcmc}. Generalizations are discussed in Sec.~\ref{general}.

\section{Model Formulation}
\label{model}
We assume $P$ persons take a test consisting of $I$ items. For simplicity, items are assumed to be multiple-choice, but polytomous or continuous-scored items could be supported. Person $p$'s response to item $i$ is denoted by the binary $X_{pi}$ ($X_{pi}=1$ is the answer was correct, $0$ otherwise).

\subsection{Unknowns}
Item responses are assumed to be driven by $C$ latent variables $\ta := (\ta_1,\dots,\ta_C)$ representing a person's ability. Let $\ta_p=(\ta_p^1,\dots,\ta_p^C)$ denote person $p$'s unknown ability and $\bta = (\ta_1,\dots,\ta_P)$. We are free to choose $\ta$'s domain $\Omega$; we choose $\Omega := [-M,M]^C$ with a large enough $M$, say, $M = 5$ ($\ta_{i,c}$ may be interpreted as the number of standard deviations away person $i$'s ability is from the average ability in dimension $c$, $c=1,\dots,C$).

A person's response to item $i$ is modeled by an Item Response Function (IRF) $P_i(\ta;\beta_i)$, where $\beta_i$ is a vector of item parameters. We represent $P_i$ as a numerical function: the $\ta$ domain is covered by a uniform grid of with $n$ bins in each dimension and meshsize $h = 2 M / n$. Let $j=(j_1,\dots,j_C)$, $1 \leq j_c \leq n$ be the bin index, $\left\{\xi_j \right\}_j$ be the bin centers, i.e., $\xi_{jc} = -M + (j_c - \frac12) h$. Let $\left\{\varphi_j\right\}_j$ denote all grid points, that is,$\varphi_{jc} = -M + j_c h$, $0 \leq j_c \leq n$.

For simplicity, we define $P_i$ as a linear interpolation from its discrete values $\beta_i := \{P_{ij} := P_i(\xi_j)\}_j$ at bin centers. Other, smoother schemes may be substituted (e.g., B-splines, as in \cite{matt_bsplines}).

Thus the unknown model parameters are $\bta$ and $\bbeta := (\beta_1,\dots,\beta_I)$. $n$ controls the IRF resolution, and is treated as a hyperparameter that is increased during estimation: as the $\bta$ estimate improve, we refine our IRF representation.

A non-uniform grid may be used instead: we explore adaptive binning in Section~\ref{adaptive_grid}, which can save much computational work. 

\subsection{Likelihood}
The density of $X_{pi}$ can be expressed as 
\begin{equation}
  f(x_{pi}|\ta_p;\beta_i) = P_i(\ta_p;\beta_i)^{x_{pi}} \left(1 - P_i(\ta_p;\beta_i)\right)^{1-x_{pi}}\,.
\end{equation}
We used here two standard assumptions of IRT \cite{junker}: experimental independence (person responses are independent) and local independence (a person's responses to items are independent). By Bayes' theorem, the posterior distribution of latent abilities given the responses is
\begin{equation}
  f(\bta|\bX;\bbeta) \propto\prod_p \prod_i f(X_{pi}|\ta_p;\beta)\,.
  \label{like}
\end{equation}

\section{Parameter Estimation Algorithm}
An iterative algorithm for any nonlinear optimization problem requires a good initial guess. The basic idea is to obtain the initial guess by continuation: solve a problem with a low IRF resolution and a small number of persons first, then gradually increase the resolution and number of people until the original problem is obtained. The continuation path is parameterized by $n$ (IRF resolution) and $T$ (simulated annealing temperature controlling the size of Monte-Carlo steps). $s=1,\dots,S$ denote the continuation step number; quantities associated with step $s$ are denoted with an $s$-superscript.

Instead of creating samples of persons of various sizes for different continuation steps, which may not represent the ability distribution, prior to the continuation we create a hierarchical clustering of persons (Sec.~\ref{miniclustering}). Groups contain persons with similar response pattern. Each clustering level conveniently corresponds to a continuation step. See Algorithm~\ref{continuation_mcmc}.

\begin{algorithm}
	\caption[]{$(\bta, \bbeta) = {\mbox{Continuation-MCMC}}(X; T_{init}, T_{decrease}, \nu)$\\\hspace{\textwidth}Estimate model parameters from responses.}
	\begin{algorithmic}
	\label{continuation_mcmc}
    \STATE Hierarchically cluster persons: $\left\{\cG^s\right\}_{s=1}^S \lla Cluster(X)$ (Sec~\ref{miniclustering}).
    \STATE Coarsen $X$ to $X^1,\dots,X^S$ by (\ref{x_averaging}).
    \STATE $s \lla 1, T \lla T_{init}, n \lla 4$.
    \STATE $\bta^s \lla$ initial guess by item clustering at level $C_s$. (Sec.\ref{initial_guess}, Eq.~(\ref{coarsest_init})).
    \STATE $(\bta^s, \bbeta^s) = {\mbox{Estimate-MCMC}}(X^s, n, T, \nu, \bta^s)$.
    \FOR{$s = 2,\dots,S$}
    	\STATE $n \lla 2 n, T \lla T / T_{decrease}$.
    	\STATE Interpolate $\bta^s \lla \I_{s-1}^s \bta^{s-1}$ (Eq.~\ref{interpolate}). 
	    \STATE $(\bta^s, \bbeta^s) = {\mbox{Estimate-MCMC}}(X^s, n, T, \nu, \bta^s)$.
   	\ENDFOR
   	\STATE $\bta \lla \bta^S, \bbeta \lla \bbeta^S$.
	\end{algorithmic}
\end{algorithm}

\subsection{Person Clustering}
\label{miniclustering}
First, we build a hierarchical clustering of persons based on their responses using the method of \cite{miniclustering}. Each person corresponds to an $I$-dimensional point $X_p = (X_{p1},\dots,X_{pI})$. The hierarchy consists of levels $\left\{\cG^s\right\}_{s=1}^S$ where each level is a set of person groups $\cG_s := \left\{G_l\right\}_{l=1}^{P^s}$.

$G^1$ consists of $g^1 = 2C$ groups, and is obtained by k-means (as opposed to a single group in \cite{miniclustering}; we need at least $C$ groups to generate the initial guess; see Sec.~\ref{initial_guess}). Each $G^s$, $s=2,\dots,S$ is obtained from the parent level $G^{s-1}$ by (1) sub-dividing each parent group into $b$ child groups using k-means within the group; and (2) improving all child centers by global k-means, where each point is reassigned to the closest of its $r \approx 5$ nearest centers. This requires maintaining at every level approximate neighboring center lists of each point and each center, which are conveniently and derived from the parent level's neighbor lists (for a child center, we use the nearest $r$ centers within its parent's child centers and the parent's neighbors' child centers; similarly for a point). The entire process requires $O(r I P \log P)$ time and $O(r I P)$ storage.

A response matrix can be calculated for each clustering level by averaging the scores of persons in each group: $X^S := X$, and for each $s = S-1,S-2,\dots,1$,
\begin{equation}
	X^{s-1}_{l,c} = \frac{\sum_{m \in \cC^{s-1}_l} |G^{s-1}_m| X^{s-1}_{m,c}}{|G^s_c|}\,,
	\quad l=1,\dots,P^s\,,\quad c = 1,\dots,C\,,
	\label{x_averaging}
\end{equation}
where $\cC^{s-1}_l$ is the set of level-$s$ child groups of 

\subsection{Initial Guess}
\label{initial_guess}
At the coarsest level ($s=1$), we cluster items to $C$ clusters $\left\{T_c\right\}_{c=1}^C$ using k-means. Note that clustering the original binary data is not meaningful, as it is very high dimensional (k-means or its discrete cousin, k-mode, are unlikely to provide good clusters). But at the coarsest grid we only have $2C$- dimensional item vectors containing averages over large person groups, so k-means should be fine.

Each item $i$ corresponds to the point $(X^1_{1,i},\dots,X^1_{g^1,i})$. Since $g^1$ is sufficiently larger than $C$, we have enough information for a meaningful clustering. For each $c=1,\dots,C$ and each person group $p=1,\dots,P$, we calculate the fraction $f_{pc}$ of correct responses of $p$ to items in $T_c$, and initialize $\ta^1_{pc}$ to the number of standard deviations away from the mean fraction; namely,
\begin{eqnarray}
	f_{pc} &=& \frac{\sum_{i \in T_c} X^1_{pi}}{|T_c|} \\
	\bar{f}_c &=& \frac{1}{P^1} \sum_{p=1}^{P^1} f_{pc} \\
	\sigma_c &=& \left(\frac{1}{P^1-1} (f_{pc} - \bar{f}_c)^2 \right)^{\frac12} \\
	\ta^1_{pc} &=& \frac{f_{pc} - \bar{f}_c}{\sigma_c}\,.
	\label{coarsest_init}
\end{eqnarray}

At subsequent levels we initialize $\bta^s$ by a piecewise constant interpolation from $\bta^{s-1}$:
\begin{equation}
	\ta^s_{pc} = \left(\I_{s-1}^s \bta^{s-1}\right)_{pc} := \ta^{s-1}_{lc}\,,\qquad c=1,\dots,C\,, l=1,\dots,P^{s-1}\,,p \in G^{s-1}_l\,.
	\label{interpolate}
\end{equation}
$\I_{s-1}^s$ is a matrix, since this is a linear operation. This initialization seems simple and adequate; if it isn't, a higher order interpolation could be considered instead, for instance,
\begin{equation}
	\ta^s_{pc} = \sum_l w_{pl} \bta^{s-1}_{lc}\,,
\end{equation}
where $l$ runs over a set of neighboring parent group centers (already available from the person clustering of Sec.~\ref{miniclustering}), $w_{pl} \propto \phi(\|X^{s-1}_l-X^s_p\|)$ are chosen to interpolate some polynomials exactly, and $\phi$ is a suitable radial basis function.

\subsection{MCMC at a Given Resolution}
In this section we assume $n$ and $T$ are fixed, and omit the $s$-superscripts from all quantities. Given the initial guess for $\bta$, we alternate between updating the IRF and $\nu$ MCMC sweeps to update $\bta$, where each sweep updates $\ta_p$ using Metropolis-Hastings steps, $p=1,\dots,P$ (Sec.~\ref{metropolis}). This is repeated until the Markov Chain converges to the stationary distribution $f(\bta,\bbeta|X)$.

\begin{algorithm}
\caption[]{$(\bta, \bbeta) = {\mbox{Estimate-MCMC}}(n, T, \nu, \bta_{init})$\\\hspace{\textwidth}
Estimate model parameters given continuation hyperparameters.}
\begin{algorithmic}
	\label{mcmc}
    \STATE Set $\bta \lla \bta_{init}$.
    \WHILE{MCMC not converged}
    	\STATE Update $\bbeta$ by the histogram rule (\ref{histogram_const}).
    	\FOR{$j=1,\dots,\nu$}
	    	\FOR{$p=1,\dots,P$}
	    		\STATE $\ta_p \lla Metropolis-Step(\ta, T, p)$) (Sec.~\ref{metropolis}).
	    	\ENDFOR
    	\ENDFOR
    \ENDWHILE
\end{algorithmic}
\end{algorithm}

\subsubsection{Updating the IRF: Histogram}
\label{histogram}
Given an IRF bin resolution $n$ and an initial guess for $\bta$, we calculate the IRF bin values as a histogram:
\begin{equation}
	\label{histogram_const}
	P_{ij} = \frac{\sum_{p \in A_j} X_{pi}}{|A_j|}\,,\qquad
	A_j := \left\{ p : \varphi_{j-1} \leq \ta_p < \varphi_j \right\}\,.
\end{equation}
Here $\ta \leq \varphi$ for vectors $\ta,\varphi \in \R^C$ is defined as elementwise $\leq$, and $j-1 = (j_1-1,\dots,j_C-1)$.
More generally, one can replace (\ref{histogram_const}) by a smoother distribution scheme, where each person contributes a term $w X_{pi}$ to the numerator and $w$ to the denominator of its own bin and several neighboring bins $j'$ where $w$ is inversely proportional to $\ta_p - \xi_{j'}$ (this is the transpose operation of a polynomial interpolation from bin centers to $\ta_p$). This may be considered when $P_i$'s representation is smoother.

\subsection{Updating $\bta$: Monte-Carlo Steps}
\label{metropolis}
From (\ref{model}) it follows that the complete conditional density of $\ta_p$ is
\begin{equation}
  f(\ta_p|rest) \propto \prod_i 
  P_i(\ta_p;\beta_i)^{x_{pi}}\left(1 - P_i(\ta_p;\beta_i)\right)^{1-x_{pi}}\,.
  \label{cond_ta}
\end{equation}
A Hastings-Metropolis step for $\ta_p$ requires a proposal distribution $q(\ta_*|\ta_p)$. We choose a symmetric $q$ that moves $\ta_p$ by a fraction of its bin size:
\begin{equation}
	q(\ta_*|\ta_p) = \Normal(\ta_p, \frac{h}{4} I_C)
	\label{proposal}
\end{equation}
where $I_C$ is the $C \times C$ identity matrix.

Similarly to simulated annealing in statistical physics, the temperature $T$ controls the step. For $T = \infty$, we always accept $\ta^*$; $T = 1$ is the standard Metropolis step; as $T \rightarrow 0$, we accept if and only if $\ta^*$ increases (\ref{cond_ta}). The acceptance probability is
\begin{equation}
	\alpha_* := \min\left\{1, e^{\log(f(\ta_*|rest)/f(\ta_p|rest))/T} \right\}\,.
	\label{acceptable}
\end{equation}

\begin{algorithm}
\caption[]{$\ta = {\mbox{Metropolis-Step}}(T, \ta_p, p)$\\\hspace{\textwidth}
Update a single person parameter given parameters given continuation hyperparameters.}
\begin{algorithmic}
	\label{metropolis_step}
    \STATE Select $\ta_* \sim q(\ta_*|\ta_p)$ (Eq.~\ref{proposal}).
	\STATE Calculate $\alpha^*$ by (\ref{acceptable}).
	\item Set $\ta_p \leftarrow \ta_*$ with probability $\alpha^*$, otherwise leave $\ta_p$ unchanged.
\end{algorithmic}
\end{algorithm}

\subsubsection{Stopping Criterion}

\subsection{Continuation Policy}
Starting from $n = 4, T=T_{init}$. At every continuation step we double the IRF resolution $n$ while decreasing $T$ by $T_{decrease}$ (Algorithm~\ref{continuation_mcmc}). The choice of parameters should be robust to different data sets. We pick
\begin{equation}
	T_{init} = 10\,,\qquad T_{decrease} = \log_{S/2} 0.1\,,
\end{equation}
so that $T=10$ at the coarsest level, $T=1$ in the middle of the continuation, and $T=0.1$ at the end. Tuning should be obtained by data experimentation. 

\section{Quality Measurement}
The model described here is actually a family of models (depending on the choice of likelihood function weighting, bin refinement strategy, etc.). It is important to compare models by their prediction quality of
person responses to a set of validation items; if a separate validation data set is not available, cross-validation can be used instead.

{\bf The convergence (equilibration) of the model should also be properly defined, either in terms of target quantities below.}

\subsubsection{Target Quantities}
A typical target quantity of interest (e.g., in NAEP) is the mean of some function $g(\cdot)$ of proficiency scores $\ta$ over all individuals in some sub-population $\G$. The Nation's Report Card reports results on the composite scale, which is a weighted average of the sub-scales, $g(\ta) = a^T \ta$ for some fixed $a$. The Nation's Report Card also reports the proportion of persons in $\G$ whose composite score is in some pre-defined achievement range, i.e.,
\begin{equation}
	g(\ta) = I_{(l,u)}(a^T \ta) =
  \begin{cases}
    1, & a^T \ta \in (l,u), \\
    0, & a^T \ta \not \in (l,u)\,.
  \end{cases}
\end{equation}

\section{Fast Multilevel MCMC}
\begin{itemize}
	\item How to measure convergence, i.e., equilibration = convergence to the stationary distribution? 
	\item How to efficiently generate independent configurations from the stationary distribution once we converged
	(so that we can estimate target quantities with a reasonably-sized sample)?
	\item Initial guess for parameters: in general, by continuation. But one should define the coarse variables
	to be able to continue from a coarser scale, and we don't have them yet. So, one could define the $\ta$'s
	from the fraction of correct responses of a person on the corresponding questions (relative to the general
	population average, which is defined as $\ta=0$ by our model).
	\item Find a coarse variable set using clustering. $\ta_p$'s should probably be clustered separately. 	Possibly also $a_i$'s and $b_i$'s; or one could just coarsen all of the $\beta_i$'s.
	\item Measure coarse variable set quality by Compatible MC (CMC)'s convergence rate. Since this should be a fast convergence for a good set, convergence of target quantities may suffice to define the convergence rate here.
\end{itemize}

% Add clustering preprocessing and full multigrid algorithm flow diagram here.


\section{Generalizations}
\label{general}

\subsection{Adaptive Binning}
\label{adaptive_grid}

\subsection{Item Types}
For simplicity, items were assumed to be multiple-choice.
\begin{itemize}
	\item Polytomous: multiple $P_i$'s - one for each response value.
	\item Continuous-scored items: {\bf is that a real-world scenario, and if it is, 
	need to describe $P_i(\ta|X)$ using appropriate grids (tables), with adaptive resolution
	according to local derivates of $X$?}
\end{itemize}

\section{Acknowledgments}
The work reported herein was supported by Educational Testing Service Research Allocation Project {\bf TBD...}.

The author would like to thank Achi Brandt for his insightful suggestions regarding the modeling and algorithm.

\bibliographystyle{plain}
\bibliography{irt_mcmc}

\end{document}