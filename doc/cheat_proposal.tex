\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{authblk}
\usepackage{mathtools}
\usepackage {graphicx}
\usepackage{subfig}

\newcommand{\cC}{\mathcal{C}}
\newcommand{\cS}{\mathcal{S}}

\title{Graph Biclustering Algorithms for Detecting Item Exposure}

\author[1]{Oren Livne}
\affil[1]{Educational Testing Service, 660 Rosedale Road, Attn: MS-12, T-197, Princeton, NJ 08540. Email: olivne@ets.org}
\date{\today}
	
\begin{document}
\maketitle

\section{Graph-based Statistical Methods for Detecting Item Exposure}
Item exposure refers to the condition of some examinees having prior access to test questions and/or answers before taking the test (e.g., \cite{eckerly}). These examinees are hereafter referred ``cheaters'', and the leaked test questions are referred to as ``exposed items''. We consider the problem of finding likely cheater sets (CSs) and corresponding exposed item sets (multiple such sets may exist, and overlap) based on their response pattern only, without additional information, e.g., a previous test result of the same examinees. Identifying a single response as fraudulent from the data alone is virtually impossible; we assume that a large fraction of the items (20\% - 40\%) were exposed {\bf as in this real-life scenario - third-party company - add details here}.

Statistical methods for detecting item exposure is a hot research topic \cite{test_fraud_book}. In particular, graph-based methods have been suggested. A {\it graph} (or network) is a mathematical structure representing pairwise connections between objects. It consists of {\it nodes} (the objects) and {\it edges} (connections between some of the objects, often carrying a weight representing the strength of connection; here we discuss {\it undirected}, i.e. symmetric connections). A {\it clique} is a subset of the nodes such that every two nodes in the clique are connected; for instance, $A$ is a clique in Fig.~\ref{graph} (a), but $B$ is not, since $x$ and $y$ are not connected.
 
Belov \cite{belov} constructed an unweighted examinee similarity graph. An edge between two examinees is added if and only if their response patterns are sufficiently similar according to the $\omega$ similarity index; see Fig.~\ref{graph} (a). The largest clique is identified using standard algorithms, and reported as a CS if its size is significantly large; the clique size null distribution is estimated using Monte-Carlo simulations. If so, the clique is removed from the graph, and the next largest clique is identified; etc. The drawbacks of this method are (a) the graph includes only examinees as nodes; items are basically aggregated in the response similarity index, making it hard to detect which items were leaked; and (b) looking for perfect cliques is very restrictive and fragile; it depends on the particular similarity index and threshold used to define graph edges. In practice, CSs may be near-cliques (e.g., set $B$ in Fig.~\ref{graph} (a)) or strongly connected clusters of nodes.

In a related field, Girish et al. \cite{collusion_stock_graph_clustering} used graph clustering to detect collusion groups of stock traders. However, the data is different than in educational applications: for each item (stock) there are many ``responses'', i.e., the act of a trader buying or selling stock to another trader. A separate {\it directed} graph of trader similarity is constructed for each stock and traders are clustered by a similarity index defined by the number of mutual nearest neighbors.

\begin{figure}
    \centering
    \subfloat[examinee similarity graph. Nodes represent examinees, and edges represent examinees who are similar. The node set $A$ is a clique, but $B$ is not, since $x$ and $y$ are not connected.]{{\includegraphics[height=6cm]{graph_with_cliques.pdf} }}
    \qquad
    \subfloat[A bi-partite graph. Red nodes represent examinees; yellow nodes represent items. An edge is placed only between a examinee $x$ and an $y$ if $x$'s response to $y$ was aberrant.]{{\includegraphics[height=6cm]{bipartite_graph.pdf} }}
    \caption{Example of graph models.}
    \label{graph}
\end{figure}

\section{New Algorithm for Detecting  and Fraudulent Examinees and Exposed Items}
We propose a new graph-based approach to detecting cheater groups and exposed items based on {\it biclustering} and inspired by {\it multiscale methods} \cite{mg_guide}. First, we build a graph consisting two types of nodes: examinees and items. An edge between a examinee and item is added if the examinee solved the item correctly, yet his/her likelihood of solving the item (estimated by an IRT model, for instance) is very small. That is, graph edges represent {\it aberrant responses}; see Fig.~\ref{graph} (b).

We will explore biclustering methods of the graph: clustering of examinee nodes, which is tied to a clustering in the item nodes. The former clustering provides CSs, while the latter provides the corresponding exposed item sets. The method contains two main steps. 

First, we construct feature vectors (of dimension $5-10$) for each examinee and item based, and define the similarity between examinees as the Euclidean distance between their feature vectors. The similarity metric was first developed by Safro et. al \cite{safro}, and applied to solving semi-supervised regression problems in \cite{lamg} , and finding descendants sharing the same DNA haplotype \cite{primal}. They are more meaningful than edge weights in defining similarity: two examinees will be classified as similar not just if they both happen to have aberrant response to the same item, but to {\it many similar items}; items are defined as similar if both had aberrant responses from {\it many similar examinees}; and so on, alternating between examinees and items. For instance, in Fig.~\ref{graph} (b), $x$ and $y$ may be considered similar, since they have four mutual aberrant item responses, but $x$ and $z$ might not, since they only share one.

Second, we cluster examinees via their feature vectors using a new hierarchical k-means algorithm. Clusters that have high intra-similarity compared with its inter-similarity are reported as CSs (the silhouette score statistic will be used to this end). The exposed item sets are derived from the items the cluster is connected to.

\subsection{Mathematical Details}
{\bf Aberration graph.} First, we build an undirected {\it bipartite} graph of examinees and items. Let $P$ be the number of examinees, $I$ the number of items. Items are dichotomous, but the methodology can be applied to continuous scores as well. Let $\theta$ be a latent examinee ability variable, and $X_{pi}$ is the random variable representing examinee $p$'s response to item $i$. Suppose that examinee $p$'s ability $\theta_p$, item $i$'s difficulty parameter $\gamma_i$, and subsequently the success probability
\begin{equation}
	P_{pi} := P \left [X_{pi}=1 | \theta_p, \gamma_i \right]\,
	\label{ppi} 
\end{equation}
have been estimated by an IRT model. Then we can define
\begin{equation}
  w_{pi} := P_{pi}^{-s} \,,
  \label{weight}
\end{equation}
where $s  > 0$ is a hyper-parameter that can be chosen higher or lower to emphasize or de-emphasize highly aberrant responses.

{\mbox{}}\\
{\bf Graph-based distances.} Next, we construct feature vectors (of dimension $5-10$) for each examinee and item. Each feature is obtained by few Gauss-Seidel relaxation sweeps, starting from random vectors  at the nodes, and normalizing the vectors to unit $L_2$ norm after each sweep. Two nodes with small $L_2$ distance have many mutual neighbors and short paths connecting them, i.e., they belong to similar {\it neighorhoods} of the graph, making them more meaningful than the size of the edge weight between them, or the shortest path length.

{\mbox{}}\\
{\bf Biclustering.} The feature vectors are clustered using a novel hierarchical, top-down clustering algorithm that produces {\it miniclusters} of examinees that have many common item neighbors. The number of clusters is not predetermined as in classical k-means; we start with a single cluster containing all examinees, and keep subdividing it until cluster radii are less than a maximum radius threshold (to be determined by numerical experimentation). The algorithm's complexity scales log-linearly with the number of examinees and linearly with the number of items. 

{\mbox{}}\\
{\bf Cheater set significance testing.} Given a cluster $\cC$, we would like to test how likely it is to be a CS. A CS is likely to have a larger intra-connectivity than inter-connectivity to the surrounding graph nodes, as examinees within the group exhibit a common pattern (at least for exposed items) not shared by other test takers. Our test statistic is the {\it mean silhouette score}, defined by
\begin{equation}
	\phi(\cC) :=  \frac{1}{|\cC|} \sum_{p \in \cC}  \frac{D_{\cC',p}- D_{\cC,p}}{\max\left\{D_{\cC',p}, D_{\cC,p} \right\}}\,,\quad
	D_{\cS, c} := \frac{1}{|\cS|-1} \sum_{p' \in S, p' \not = p} d_{p,p'}\,.
	\label{sil}
\end{equation}
where $\cC'$ is the complement set of $\cC$. The null distribution of of silhouette scores is estimated by simulation: given the latent abilities $\left\{\theta_p\right\}_p$ and item response functions, we generate a $P \times I$ matrix of random item responses, and run biclustering and obtain a list of examinee mini-clusters and corresponding silhouette scores. We construct a silhouette score distribution from multiple random experiments. Since each experiment yields $O(P)$ clusters (most of which contain $O(1)$ examinees), we can obtain a large sample of scores with a reasonable number of experiments (perhaps $10-50$, and probably bounded as $P \longrightarrow \infty$. Given a score $\phi(\cC)$, we can now determine its $p$-value in the distribution and flag all clusters with $p$-value less than a specified value, say, $0.05$, as cheater sets.

{\mbox{}}\\
{\bf Iterative refinement.} Optionally, once CS have been identified, one could improve the results by rerunning the IRT model without the responses of cheaters to exposed items, re-estimate the cheater sets, and repeat. One such iteration is probably sufficient.

\section{Study Design for Detecting Item Exposure}
The project will first demonstrate the potential of the detection algorithm on several simulated data sets: 
\begin{itemize}
	\item Single cheater set of size $G$ ($1\%-5\%$ of examinees) corresponding to $K=20\%-40\%$ exposed items.
	\item Two disjoint collusion groups corresponding to two disjoint sets of leaked items.
	\item Two disjoint collusion groups with overlapping leaked item sets. Degree of overlap is a parameter.
	\item Two overlapping collusion groups with non-overlapping leaked item sets.
	\item Two overlapping collusion groups with overlapping leaked item sets.
	\item Real-world data set {\bf add details here} with 1636 examinees and 170 items, where cheater sets were identified {\bf by other methods}.
\end{itemize}
For each step, we will
\begin{itemize}
	\item Calculate cheater sets and exposed item for various hyperparameter values, obtaining an ROC (type I error vs. type II error) curve to understand the power and tradeoffs of the method.
	\item Compare with existing methods and examine how the results differ.
	\item Make an overall conclusion regarding the performance of the new algorithm compared with existing algorithms. A part of this step will be the determination of whether analyzing both item scores and response times has a benefit over analyzing item scores only.
\end{itemize}

\bibliographystyle{plain}
\bibliography{irt_mcmc}

\end{document}